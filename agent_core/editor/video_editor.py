"""
å‹•ç”»ç·¨é›†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ã®ç·¨é›†ã€åˆæˆã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆè¿½åŠ 
"""

import os
import tempfile
from pathlib import Path
from typing import List, Dict, Any, Optional
import subprocess
import json

class VideoEditor:
    """å‹•ç”»ç·¨é›†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.temp_dir = Path(tempfile.gettempdir()) / "pv_editor"
        self.temp_dir.mkdir(exist_ok=True)
    
    def merge_scenes(self, 
                    scene_videos: List[str],
                    audio_file: str,
                    output_path: str,
                    transitions: str = "crossfade",
                    progress_callback: Optional[callable] = None) -> Dict[str, Any]:
        """
        è¤‡æ•°ã®ã‚·ãƒ¼ãƒ³å‹•ç”»ã‚’çµåˆã—ã¦éŸ³æ¥½ã¨åŒæœŸ
        
        Args:
            scene_videos: ã‚·ãƒ¼ãƒ³å‹•ç”»ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
            audio_file: éŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            transitions: ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³åŠ¹æœ
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        
        Returns:
            ç·¨é›†çµæœ
        """
        try:
            if progress_callback:
                progress_callback(0.1, "ğŸ¬ å‹•ç”»ç·¨é›†ã‚’é–‹å§‹...")
            
            # FFmpegã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã‚’çµåˆ
            concat_file = self.temp_dir / "concat_list.txt"
            with open(concat_file, 'w') as f:
                for video in scene_videos:
                    f.write(f"file '{video}'\n")
            
            if progress_callback:
                progress_callback(0.3, "ğŸ“¹ ã‚·ãƒ¼ãƒ³ã‚’çµåˆä¸­...")
            
            # å‹•ç”»ã‚’çµåˆ
            merged_video = self.temp_dir / "merged_video.mp4"
            cmd = [
                'ffmpeg', '-f', 'concat', '-safe', '0',
                '-i', str(concat_file),
                '-c', 'copy',
                str(merged_video),
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                return {
                    "status": "error",
                    "message": f"å‹•ç”»çµåˆã‚¨ãƒ©ãƒ¼: {result.stderr}"
                }
            
            if progress_callback:
                progress_callback(0.6, "ğŸµ éŸ³æ¥½ã‚’è¿½åŠ ä¸­...")
            
            # éŸ³æ¥½ã‚’è¿½åŠ 
            cmd = [
                'ffmpeg',
                '-i', str(merged_video),
                '-i', audio_file,
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-shortest',
                output_path,
                '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                if progress_callback:
                    progress_callback(1.0, "âœ… ç·¨é›†å®Œäº†ï¼")
                
                return {
                    "status": "success",
                    "output_path": output_path,
                    "duration": self._get_video_duration(output_path)
                }
            else:
                return {
                    "status": "error",
                    "message": f"éŸ³æ¥½è¿½åŠ ã‚¨ãƒ©ãƒ¼: {result.stderr}"
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"ç·¨é›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            }
    
    def add_transitions(self,
                       video_path: str,
                       transition_type: str = "fade",
                       duration: float = 1.0) -> str:
        """
        ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³åŠ¹æœã‚’è¿½åŠ 
        
        Args:
            video_path: å‹•ç”»ãƒ‘ã‚¹
            transition_type: ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—
            duration: ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³æ™‚é–“
        
        Returns:
            å‡ºåŠ›ãƒ‘ã‚¹
        """
        output_path = self.temp_dir / f"transition_{Path(video_path).name}"
        
        # FFmpegãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³è¿½åŠ 
        if transition_type == "fade":
            filter_str = f"fade=t=in:st=0:d={duration},fade=t=out:st=-{duration}:d={duration}"
        elif transition_type == "crossfade":
            filter_str = f"xfade=transition=fade:duration={duration}:offset=0"
        else:
            filter_str = ""
        
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-vf', filter_str,
            '-c:a', 'copy',
            str(output_path),
            '-y'
        ]
        
        subprocess.run(cmd, capture_output=True)
        return str(output_path)
    
    def add_text_overlay(self,
                        video_path: str,
                        text: str,
                        position: str = "bottom",
                        font_size: int = 48,
                        color: str = "white") -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’è¿½åŠ 
        
        Args:
            video_path: å‹•ç”»ãƒ‘ã‚¹
            text: è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆ
            position: è¡¨ç¤ºä½ç½®
            font_size: ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
            color: ãƒ†ã‚­ã‚¹ãƒˆè‰²
        
        Returns:
            å‡ºåŠ›ãƒ‘ã‚¹
        """
        output_path = self.temp_dir / f"text_{Path(video_path).name}"
        
        # ä½ç½®ã‚’è¨­å®š
        if position == "top":
            pos_str = "x=(w-text_w)/2:y=50"
        elif position == "center":
            pos_str = "x=(w-text_w)/2:y=(h-text_h)/2"
        else:  # bottom
            pos_str = "x=(w-text_w)/2:y=h-text_h-50"
        
        # FFmpegã§ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        filter_str = f"drawtext=text='{text}':fontsize={font_size}:fontcolor={color}:{pos_str}"
        
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-vf', filter_str,
            '-c:a', 'copy',
            str(output_path),
            '-y'
        ]
        
        subprocess.run(cmd, capture_output=True)
        return str(output_path)
    
    def add_filter(self,
                  video_path: str,
                  filter_type: str = "vintage") -> str:
        """
        ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’è¿½åŠ 
        
        Args:
            video_path: å‹•ç”»ãƒ‘ã‚¹
            filter_type: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¿ã‚¤ãƒ—
        
        Returns:
            å‡ºåŠ›ãƒ‘ã‚¹
        """
        output_path = self.temp_dir / f"filter_{Path(video_path).name}"
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å®šç¾©
        filters = {
            "vintage": "curves=vintage",
            "grayscale": "colorchannelmixer=.3:.4:.3:0:.3:.4:.3:0:.3:.4:.3",
            "blur": "boxblur=5:1",
            "sharpen": "unsharp=5:5:1.0:5:5:0.0",
            "brightness": "eq=brightness=0.1",
            "contrast": "eq=contrast=1.2",
            "sepia": "colorchannelmixer=.393:.769:.189:0:.349:.686:.168:0:.272:.534:.131"
        }
        
        filter_str = filters.get(filter_type, "")
        
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-vf', filter_str,
            '-c:a', 'copy',
            str(output_path),
            '-y'
        ]
        
        subprocess.run(cmd, capture_output=True)
        return str(output_path)
    
    def adjust_speed(self,
                    video_path: str,
                    speed: float = 1.0) -> str:
        """
        å‹•ç”»ã®é€Ÿåº¦ã‚’èª¿æ•´
        
        Args:
            video_path: å‹•ç”»ãƒ‘ã‚¹
            speed: é€Ÿåº¦å€ç‡
        
        Returns:
            å‡ºåŠ›ãƒ‘ã‚¹
        """
        output_path = self.temp_dir / f"speed_{Path(video_path).name}"
        
        # FFmpegã§é€Ÿåº¦èª¿æ•´
        video_filter = f"setpts={1/speed}*PTS"
        audio_filter = f"atempo={speed}"
        
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-filter:v', video_filter,
            '-filter:a', audio_filter,
            str(output_path),
            '-y'
        ]
        
        subprocess.run(cmd, capture_output=True)
        return str(output_path)
    
    def extract_clip(self,
                    video_path: str,
                    start_time: float,
                    end_time: float) -> str:
        """
        å‹•ç”»ã®ä¸€éƒ¨ã‚’åˆ‡ã‚Šå‡ºã—
        
        Args:
            video_path: å‹•ç”»ãƒ‘ã‚¹
            start_time: é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰
            end_time: çµ‚äº†æ™‚é–“ï¼ˆç§’ï¼‰
        
        Returns:
            å‡ºåŠ›ãƒ‘ã‚¹
        """
        output_path = self.temp_dir / f"clip_{Path(video_path).name}"
        duration = end_time - start_time
        
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-ss', str(start_time),
            '-t', str(duration),
            '-c', 'copy',
            str(output_path),
            '-y'
        ]
        
        subprocess.run(cmd, capture_output=True)
        return str(output_path)
    
    def create_thumbnail(self,
                        video_path: str,
                        time_position: float = 0) -> str:
        """
        ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã‚’ç”Ÿæˆ
        
        Args:
            video_path: å‹•ç”»ãƒ‘ã‚¹
            time_position: ã‚µãƒ ãƒã‚¤ãƒ«ä½ç½®ï¼ˆç§’ï¼‰
        
        Returns:
            ç”»åƒãƒ‘ã‚¹
        """
        output_path = self.temp_dir / f"thumb_{Path(video_path).stem}.jpg"
        
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-ss', str(time_position),
            '-vframes', '1',
            str(output_path),
            '-y'
        ]
        
        subprocess.run(cmd, capture_output=True)
        return str(output_path)
    
    def _get_video_duration(self, video_path: str) -> float:
        """å‹•ç”»ã®é•·ã•ã‚’å–å¾—"""
        cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            video_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            data = json.loads(result.stdout)
            return float(data.get('format', {}).get('duration', 0))
        
        return 0
    
    def apply_batch_edits(self,
                         video_path: str,
                         edits: List[Dict[str, Any]],
                         progress_callback: Optional[callable] = None) -> str:
        """
        è¤‡æ•°ã®ç·¨é›†ã‚’ä¸€æ‹¬é©ç”¨
        
        Args:
            video_path: å‹•ç”»ãƒ‘ã‚¹
            edits: ç·¨é›†ãƒªã‚¹ãƒˆ
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        
        Returns:
            æœ€çµ‚å‡ºåŠ›ãƒ‘ã‚¹
        """
        current_path = video_path
        total_edits = len(edits)
        
        for i, edit in enumerate(edits):
            if progress_callback:
                progress = (i + 1) / total_edits
                progress_callback(progress, f"ç·¨é›† {i+1}/{total_edits}: {edit.get('type', 'unknown')}")
            
            edit_type = edit.get('type')
            
            if edit_type == 'transition':
                current_path = self.add_transitions(
                    current_path,
                    edit.get('transition_type', 'fade'),
                    edit.get('duration', 1.0)
                )
            elif edit_type == 'text':
                current_path = self.add_text_overlay(
                    current_path,
                    edit.get('text', ''),
                    edit.get('position', 'bottom'),
                    edit.get('font_size', 48),
                    edit.get('color', 'white')
                )
            elif edit_type == 'filter':
                current_path = self.add_filter(
                    current_path,
                    edit.get('filter_type', 'vintage')
                )
            elif edit_type == 'speed':
                current_path = self.adjust_speed(
                    current_path,
                    edit.get('speed', 1.0)
                )
        
        if progress_callback:
            progress_callback(1.0, "âœ… å…¨ç·¨é›†å®Œäº†")
        
        return current_path