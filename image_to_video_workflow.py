#!/usr/bin/env python3
"""
ç”»åƒâ†’å‹•ç”»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆv5.0.0ï¼‰
1. Midjourneyç”»åƒç”Ÿæˆ
2. Klingå‹•ç”»ç”Ÿæˆ
æ—¥æœ¬äººå¥³æ€§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä¸€è²«æ€§ã‚’ä¿æŒ
"""

import streamlit as st
import requests
import json
import time
from typing import Dict, Any, List, Optional
from pathlib import Path

class ImageToVideoWorkflow:
    """ç”»åƒâ†’å‹•ç”»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆKlingãƒ¡ã‚¤ãƒ³ï¼‰"""
    
    def __init__(self):
        # APIã‚­ãƒ¼è¨­å®š
        self.piapi_key = st.session_state.get('api_keys', {}).get('piapi', '328fcfae00e3efcfb895f1d0c916ce6a2657daecff3f748f174b12bd03402f6b')
        self.piapi_xkey = st.session_state.get('api_keys', {}).get('piapi_xkey', '5e6dd612b7acee46b055acf37d314c90f1c118fde228c218c3722c132ae79bf4')
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šï¼ˆæ—¥æœ¬äººå¥³æ€§ï¼‰
        self.character_base = "beautiful Japanese woman, 25 years old, long black hair, elegant features"
        self.character_style = "photorealistic, high quality, professional photography"
    
    def generate_detailed_script(self, 
                               title: str, 
                               description: str,
                               duration: int = 180) -> Dict[str, Any]:
        """
        è©³ç´°ãªå°æœ¬ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§é‡è¦–ï¼‰
        
        Args:
            title: PVã‚¿ã‚¤ãƒˆãƒ«
            description: æ¦‚è¦èª¬æ˜
            duration: å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰
        
        Returns:
            è©³ç´°å°æœ¬
        """
        
        # ã‚·ãƒ¼ãƒ³æ•°ã‚’è¨ˆç®—ï¼ˆå„ã‚·ãƒ¼ãƒ³8ç§’ï¼‰
        num_scenes = duration // 8
        
        script = {
            'title': title,
            'duration': duration,
            'character': self.character_base,
            'scenes': []
        }
        
        # å„ã‚·ãƒ¼ãƒ³ã®è©³ç´°å°æœ¬ã‚’ç”Ÿæˆ
        for i in range(num_scenes):
            scene = {
                'scene_number': i + 1,
                'duration': 8,
                'time_range': f"{i*8}-{(i+1)*8}s",
                
                # ã‚¹ãƒˆãƒ¼ãƒªãƒ¼è¦ç´ ï¼ˆè©³ç´°åŒ–ï¼‰
                'narrative': self._generate_scene_narrative(i, num_scenes, title),
                
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æå†™ï¼ˆä¸€è²«æ€§é‡è¦–ï¼‰
                'character_description': self._generate_character_description(i, num_scenes),
                
                # Midjourneyãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç”»åƒç”Ÿæˆç”¨ï¼‰
                'midjourney_prompt': '',  # å¾Œã§ç”Ÿæˆ
                
                # Klingå‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå‹•ç”»åŒ–ç”¨ï¼‰
                'kling_prompt': '',  # å¾Œã§ç”Ÿæˆ
                
                # ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯è¨­å®š
                'camera_movement': self._get_camera_movement(i, num_scenes)
            }
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            scene['midjourney_prompt'] = self._create_midjourney_prompt(scene)
            scene['kling_prompt'] = self._create_kling_prompt(scene)
            
            script['scenes'].append(scene)
        
        return script
    
    def _generate_scene_narrative(self, scene_index: int, total_scenes: int, title: str) -> str:
        """ã‚·ãƒ¼ãƒ³ã®ãƒŠãƒ©ãƒ†ã‚£ãƒ–ç”Ÿæˆ"""
        
        # èµ·æ‰¿è»¢çµæ§‹æˆ
        if scene_index == 0:
            return f"ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°: {title}ã®ç‰©èªãŒå§‹ã¾ã‚‹ã€‚ä¸»äººå…¬ã®æ—¥æœ¬äººå¥³æ€§ãŒç™»å ´ã€‚æœã®å…‰ã®ä¸­ã§æ–°ã—ã„ä¸€æ—¥ãŒå§‹ã¾ã‚‹ã€‚"
        elif scene_index < total_scenes // 3:
            return f"å°å…¥éƒ¨: ä¸»äººå…¬ãŒæ—¥å¸¸ã‹ã‚‰æ—…ç«‹ã¤æº–å‚™ã‚’ã™ã‚‹ã€‚æœŸå¾…ã¨ä¸å®‰ãŒå…¥ã‚Šæ··ã˜ã‚‹è¡¨æƒ…ã€‚"
        elif scene_index < total_scenes * 2 // 3:
            return f"å±•é–‹éƒ¨: å†’é™ºã®ä¸­ã§æ§˜ã€…ãªä½“é¨“ã‚’ã™ã‚‹ä¸»äººå…¬ã€‚æˆé•·ã¨ç™ºè¦‹ã®ç¬é–“ã€‚"
        elif scene_index < total_scenes - 1:
            return f"ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹: æœ€ã‚‚é‡è¦ãªç¬é–“ã«ç›´é¢ã™ã‚‹ä¸»äººå…¬ã€‚æ±ºæ„ã¨å‹‡æ°—ã€‚"
        else:
            return f"ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°: ç‰©èªã®çµæœ«ã€‚æ–°ã—ã„è‡ªåˆ†ã‚’è¦‹ã¤ã‘ãŸä¸»äººå…¬ã®æº€è¶³ã’ãªè¡¨æƒ…ã€‚"
    
    def _generate_character_description(self, scene_index: int, total_scenes: int) -> str:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æå†™ï¼ˆä¸€è²«æ€§ä¿æŒï¼‰"""
        
        # åŸºæœ¬è¨­å®šï¼ˆå…¨ã‚·ãƒ¼ãƒ³å…±é€šï¼‰
        base = "beautiful Japanese woman, 25 years old, long black hair, delicate features"
        
        # ã‚·ãƒ¼ãƒ³ã”ã¨ã®æœè£…ãƒ»è¡¨æƒ…
        if scene_index == 0:
            return f"{base}, wearing white summer dress, gentle smile, morning sunlight"
        elif scene_index < total_scenes // 2:
            return f"{base}, wearing white summer dress, thoughtful expression, natural lighting"
        else:
            return f"{base}, wearing white summer dress, confident smile, golden hour lighting"
    
    def _get_camera_movement(self, scene_index: int, total_scenes: int) -> Dict[str, Any]:
        """ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯è¨­å®š"""
        
        movements = [
            {"type": "zoom_in", "horizontal": 0, "vertical": 0, "zoom": 10},
            {"type": "pan_right", "horizontal": 10, "vertical": 0, "zoom": 0},
            {"type": "tilt_up", "horizontal": 0, "vertical": 10, "zoom": 0},
            {"type": "orbit", "horizontal": -10, "vertical": 5, "zoom": 5},
            {"type": "static", "horizontal": 0, "vertical": 0, "zoom": 0}
        ]
        
        return movements[scene_index % len(movements)]
    
    def _create_midjourney_prompt(self, scene: Dict[str, Any]) -> str:
        """Midjourneyç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        
        prompt = f"{scene['character_description']}, {scene['narrative']}, "
        prompt += f"{self.character_style}, cinematic composition, "
        prompt += f"8k resolution, professional photography --ar 16:9 --v 6 --style raw"
        
        return prompt
    
    def _create_kling_prompt(self, scene: Dict[str, Any]) -> str:
        """Klingå‹•ç”»ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        
        camera = scene['camera_movement']
        
        prompt = f"{scene['character_description']} in motion, "
        prompt += f"{camera['type']} camera movement, "
        prompt += f"smooth cinematic sequence, natural movement"
        
        return prompt
    
    def generate_image_with_midjourney(self, prompt: str) -> Dict[str, Any]:
        """Midjourneyã§ç”»åƒç”Ÿæˆ"""
        
        # PIAPI v1 APIã‚’ä½¿ç”¨
        url = "https://api.piapi.ai/api/v1/task"
        
        headers = {
            "X-API-Key": self.piapi_xkey,
            "Content-Type": "application/json"
        }
        
        # Midjourneyç”¨ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
        payload = {
            "model": "midjourney",
            "task_type": "imagine",
            "input": {
                "prompt": prompt + " --ar 16:9 --v 6",  # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¿½åŠ 
                "process_mode": "fast"
            },
            "config": {
                "service_mode": "public",
                "webhook_config": {
                    "endpoint": "",
                    "secret": ""
                }
            }
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                
                if result.get('code') == 200:
                    data = result.get('data', {})
                    task_id = data.get('task_id')
                    
                    if task_id:
                        st.info(f"ğŸ¨ Midjourney Task ID: {task_id[:8]}...")
                        
                        # ãƒãƒ¼ãƒªãƒ³ã‚°ã—ã¦çµæœå–å¾—
                        image_url = self._poll_midjourney_task(task_id)
                        
                        if image_url:
                            return {
                                'status': 'success',
                                'image_url': image_url,
                                'task_id': task_id,
                                'message': 'Midjourneyç”»åƒç”ŸæˆæˆåŠŸ'
                            }
                        else:
                            return {
                                'status': 'error',
                                'message': 'Midjourneyç”»åƒç”Ÿæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ'
                            }
                    else:
                        return {
                            'status': 'error',
                            'message': 'Task ID ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ'
                        }
                else:
                    return {
                        'status': 'error',
                        'message': f'API Error: {result.get("message", "Unknown error")}'
                    }
            else:
                return {
                    'status': 'error',
                    'message': f'HTTP Error: {response.status_code}'
                }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': f'Exception: {str(e)}'
            }
    
    def _poll_midjourney_task(self, task_id: str, max_attempts: int = 60) -> Optional[str]:
        """Midjourneyã‚¿ã‚¹ã‚¯ã®ãƒãƒ¼ãƒªãƒ³ã‚°ï¼ˆæœ€å¤§3åˆ†å¾…æ©Ÿï¼‰"""
        
        # PIAPI v1 APIã®ã‚¿ã‚¹ã‚¯çŠ¶æ…‹ç¢ºèª
        url = f"https://api.piapi.ai/api/v1/task/{task_id}"
        headers = {"X-API-Key": self.piapi_xkey}
        
        progress_text = st.empty()
        
        for i in range(max_attempts):
            progress_text.text(f"â³ Midjourneyå‡¦ç†ä¸­... [{i+1}/{max_attempts}]")
            
            try:
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    if result.get('code') == 200:
                        data = result.get('data', {})
                        status = data.get('status', 'pending')
                        
                        if status == 'completed':
                            output = data.get('output', {})
                            
                            # Midjourneyã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèª
                            # ç”»åƒURLã®å–å¾—ï¼ˆè¤‡æ•°ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œï¼‰
                            image_url = None
                            
                            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: image_urlç›´æ¥
                            if output.get('image_url'):
                                image_url = output['image_url']
                            
                            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: imagesé…åˆ—
                            elif output.get('images') and len(output['images']) > 0:
                                image_url = output['images'][0]
                            
                            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: imageUrlsé…åˆ—
                            elif output.get('imageUrls') and len(output['imageUrls']) > 0:
                                image_url = output['imageUrls'][0]
                            
                            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: urlç›´æ¥
                            elif output.get('url'):
                                image_url = output['url']
                            
                            # ãƒ‘ã‚¿ãƒ¼ãƒ³5: resultå†…
                            elif output.get('result'):
                                if isinstance(output['result'], str):
                                    image_url = output['result']
                                elif isinstance(output['result'], dict):
                                    image_url = output['result'].get('url') or output['result'].get('image_url')
                            
                            if image_url:
                                progress_text.success("âœ… Midjourneyç”»åƒç”Ÿæˆå®Œäº†!")
                                return image_url
                            else:
                                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                                st.warning(f"ç”»åƒURLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Output: {output}")
                                return None
                        
                        elif status in ['failed', 'error', 'cancelled']:
                            error_msg = data.get('error', {}).get('message', 'Unknown error')
                            progress_text.error(f"âŒ ç”Ÿæˆå¤±æ•—: {error_msg}")
                            return None
                
            except Exception as e:
                if i == max_attempts - 1:
                    progress_text.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            time.sleep(3)  # 3ç§’å¾…æ©Ÿ
        
        progress_text.warning("â±ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return None
    
    def generate_video_with_kling(self, 
                                 image_url: str,
                                 prompt: str,
                                 duration: int = 5,
                                 camera_horizontal: int = 0,
                                 camera_vertical: int = 0,
                                 camera_zoom: int = 0) -> Dict[str, Any]:
        """Klingã§ç”»åƒã‹ã‚‰å‹•ç”»ç”Ÿæˆï¼ˆImage-to-Videoï¼‰"""
        
        url = "https://api.piapi.ai/api/v1/task"
        
        headers = {
            "X-API-Key": self.piapi_xkey,
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "kling",
            "task_type": "video_generation",
            "input": {
                "prompt": prompt,
                "image_url": image_url,  # ç”»åƒURLã‚’è¿½åŠ 
                "negative_prompt": "",
                "cfg_scale": 0.5,
                "duration": duration,
                "aspect_ratio": "16:9",
                "camera_control": {
                    "type": "simple",
                    "config": {
                        "horizontal": camera_horizontal,
                        "vertical": camera_vertical,
                        "pan": 0,
                        "tilt": 0,
                        "roll": 0,
                        "zoom": camera_zoom
                    }
                },
                "mode": "std"
            },
            "config": {
                "service_mode": "public",
                "webhook_config": {
                    "endpoint": "",
                    "secret": ""
                }
            }
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                
                if result.get('code') == 200:
                    data = result.get('data', {})
                    task_id = data.get('task_id')
                    
                    if task_id:
                        # ãƒãƒ¼ãƒªãƒ³ã‚°ã—ã¦çµæœå–å¾—
                        video_url = self._poll_kling_task(task_id)
                        
                        if video_url:
                            return {
                                'status': 'success',
                                'video_url': video_url,
                                'task_id': task_id
                            }
            
            return {'status': 'error', 'message': f'Klingå¤±æ•—: {response.status_code}'}
            
        except Exception as e:
            return {'status': 'error', 'message': f'Klingä¾‹å¤–: {str(e)}'}
    
    def _poll_kling_task(self, task_id: str, max_attempts: int = 120) -> Optional[str]:
        """Klingã‚¿ã‚¹ã‚¯ã®ãƒãƒ¼ãƒªãƒ³ã‚°ï¼ˆæœ€å¤§20åˆ†å¾…æ©Ÿï¼‰"""
        
        url = f"https://api.piapi.ai/api/v1/task/{task_id}"
        headers = {"X-API-Key": self.piapi_xkey}
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºï¼ˆStreamlitï¼‰
        if hasattr(st, 'progress'):
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        for i in range(max_attempts):
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
            if hasattr(st, 'progress'):
                progress = (i + 1) / max_attempts
                progress_bar.progress(progress)
                status_text.text(f"â³ Klingå‹•ç”»ç”Ÿæˆä¸­... [{i+1}/{max_attempts}] ({i*10}ç§’çµŒé)")
            
            time.sleep(10)  # 10ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
            
            try:
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    result = response.json()
                    data = result.get('data', {})
                    status = data.get('status', 'unknown')
                    
                    if status == 'completed':
                        output = data.get('output', {})
                        works = output.get('works', [])
                        
                        if works and len(works) > 0:
                            for work in works:
                                if work.get('resource'):
                                    return work['resource']
                    
                    elif status in ['failed', 'error']:
                        return None
                        
            except Exception:
                pass
        
        return None
    
    def process_scene(self, scene: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚·ãƒ¼ãƒ³ã‚’å‡¦ç†ï¼ˆç”»åƒç”Ÿæˆâ†’å‹•ç”»ç”Ÿæˆï¼‰"""
        
        st.markdown(f"### ğŸ¬ ã‚·ãƒ¼ãƒ³{scene['scene_number']}ã®å‡¦ç†")
        
        # ã‚·ãƒ¼ãƒ³ã®è©³ç´°ã‚’è¡¨ç¤º
        with st.expander(f"ğŸ“ ã‚·ãƒ¼ãƒ³{scene['scene_number']}ã®è©³ç´°", expanded=True):
            st.write(f"**ãƒŠãƒ©ãƒ†ã‚£ãƒ–:** {scene['narrative']}")
            st.write(f"**ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:** {scene['character_description']}")
            st.write(f"**æ™‚é–“:** {scene['time_range']}")
        
        # ç”»åƒç”Ÿæˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("#### ğŸ¨ ç”»åƒç”Ÿæˆ")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç·¨é›†å¯èƒ½ã«ã™ã‚‹
        edited_prompt = st.text_area(
            f"Midjourneyãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç·¨é›†å¯èƒ½ï¼‰",
            value=scene['midjourney_prompt'],
            key=f"prompt_scene_{scene['scene_number']}",
            height=100
        )
        
        # ç”»åƒç”Ÿæˆãƒœã‚¿ãƒ³
        col1, col2 = st.columns([1, 3])
        with col1:
            generate_image = st.button(
                "ğŸ¨ ç”»åƒç”Ÿæˆ",
                key=f"gen_img_{scene['scene_number']}",
                type="primary"
            )
        with col2:
            regenerate_image = st.button(
                "ğŸ”„ ç”»åƒå†ç”Ÿæˆ",
                key=f"regen_img_{scene['scene_number']}"
            )
        
        # ç”»åƒç”Ÿæˆ/å†ç”Ÿæˆå‡¦ç†
        image_result = None
        if generate_image or regenerate_image:
            with st.spinner(f"ğŸ¨ ç”»åƒç”Ÿæˆä¸­..."):
                image_result = self.generate_image_with_midjourney(edited_prompt)
                
                if image_result['status'] == 'success':
                    st.success("âœ… ç”»åƒç”ŸæˆæˆåŠŸ")
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                    st.session_state[f"image_url_scene_{scene['scene_number']}"] = image_result['image_url']
                else:
                    st.error(f"âŒ ç”»åƒç”Ÿæˆå¤±æ•—: {image_result.get('message')}")
                    return image_result
        
        # ä¿å­˜ã•ã‚ŒãŸç”»åƒã‚’è¡¨ç¤º
        saved_image_url = st.session_state.get(f"image_url_scene_{scene['scene_number']}")
        if saved_image_url:
            st.image(saved_image_url, caption=f"ã‚·ãƒ¼ãƒ³{scene['scene_number']}")
            image_result = {'status': 'success', 'image_url': saved_image_url}
        elif not image_result:
            st.info("ğŸ‘† ä¸Šã®ãƒœã‚¿ãƒ³ã§ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
            return {'status': 'pending', 'message': 'ç”»åƒç”Ÿæˆå¾…ã¡'}
        
        # å‹•ç”»ç”Ÿæˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("#### ğŸ¥ å‹•ç”»ç”Ÿæˆ")
        
        # å‹•ç”»ç”Ÿæˆãƒœã‚¿ãƒ³ï¼ˆç”»åƒãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
        if image_result and image_result['status'] == 'success':
            # Klingå‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç·¨é›†å¯èƒ½ã«ã™ã‚‹
            edited_video_prompt = st.text_area(
                f"Klingå‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç·¨é›†å¯èƒ½ï¼‰",
                value=scene['kling_prompt'],
                key=f"video_prompt_scene_{scene['scene_number']}",
                height=80
            )
            
            # ã‚«ãƒ¡ãƒ©è¨­å®š
            col1, col2, col3 = st.columns(3)
            with col1:
                horizontal = st.slider(
                    "æ°´å¹³ç§»å‹•",
                    -20, 20,
                    scene['camera_movement']['horizontal'],
                    key=f"h_scene_{scene['scene_number']}"
                )
            with col2:
                vertical = st.slider(
                    "å‚ç›´ç§»å‹•",
                    -20, 20,
                    scene['camera_movement']['vertical'],
                    key=f"v_scene_{scene['scene_number']}"
                )
            with col3:
                zoom = st.slider(
                    "ã‚ºãƒ¼ãƒ ",
                    -20, 20,
                    scene['camera_movement']['zoom'],
                    key=f"z_scene_{scene['scene_number']}"
                )
            
            # å‹•ç”»ç”Ÿæˆãƒœã‚¿ãƒ³
            if st.button(f"ğŸ¥ å‹•ç”»ç”Ÿæˆ", key=f"gen_video_{scene['scene_number']}", type="primary"):
                with st.spinner(f"ğŸ¥ Klingå‹•ç”»ç”Ÿæˆä¸­ï¼ˆæœ€å¤§20åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰..."):
                    video_result = self.generate_video_with_kling(
                        image_url=image_result['image_url'],
                        prompt=edited_video_prompt,
                        duration=scene['duration'],
                        camera_movement={
                            "horizontal": horizontal,
                            "vertical": vertical,
                            "zoom": zoom
                        }
                    )
                    
                    if video_result['status'] == 'success':
                        st.success("âœ… å‹•ç”»ç”ŸæˆæˆåŠŸ")
                        st.session_state[f"video_url_scene_{scene['scene_number']}"] = video_result['video_url']
                    else:
                        st.error(f"âŒ å‹•ç”»ç”Ÿæˆå¤±æ•—: {video_result.get('message')}")
            
            # ä¿å­˜ã•ã‚ŒãŸå‹•ç”»ã‚’è¡¨ç¤º
            saved_video_url = st.session_state.get(f"video_url_scene_{scene['scene_number']}")
            if saved_video_url:
                st.video(saved_video_url)
                video_result = {'status': 'success', 'video_url': saved_video_url}
            else:
                video_result = {'status': 'pending'}
        else:
            st.info("ğŸ‘† å…ˆã«ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
            video_result = {'status': 'pending'}
        
        return {
            'scene_number': scene['scene_number'],
            'image_url': image_result.get('image_url'),
            'video_url': video_result.get('video_url'),
            'status': video_result.get('status')
        }
    
    def execute_workflow(self, title: str, description: str, duration: int = 180) -> List[Dict[str, Any]]:
        """å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ"""
        
        # Step 1: è©³ç´°å°æœ¬ç”Ÿæˆ
        st.markdown("## ğŸ“ Step 1: è©³ç´°å°æœ¬ç”Ÿæˆ")
        script = self.generate_detailed_script(title, description, duration)
        
        # å°æœ¬è¡¨ç¤º
        with st.expander("ğŸ“œ ç”Ÿæˆã•ã‚ŒãŸå°æœ¬", expanded=False):
            for scene in script['scenes']:
                st.markdown(f"**ã‚·ãƒ¼ãƒ³{scene['scene_number']}** ({scene['time_range']})")
                st.write(f"ãƒŠãƒ©ãƒ†ã‚£ãƒ–: {scene['narrative']}")
                st.write(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {scene['character_description']}")
                st.write(f"Midjourneyãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {scene['midjourney_prompt'][:100]}...")
                st.write("---")
        
        # Step 2: å„ã‚·ãƒ¼ãƒ³ã‚’å‡¦ç†
        st.markdown("## ğŸ¬ Step 2: ç”»åƒç”Ÿæˆâ†’å‹•ç”»ç”Ÿæˆ")
        results = []
        
        for scene in script['scenes']:
            result = self.process_scene(scene)
            results.append(result)
        
        # Step 3: çµæœã‚µãƒãƒªãƒ¼
        st.markdown("## ğŸ“Š Step 3: ç”Ÿæˆçµæœ")
        
        success_count = sum(1 for r in results if r.get('status') == 'success')
        st.metric("æˆåŠŸã—ãŸã‚·ãƒ¼ãƒ³", f"{success_count}/{len(results)}")
        
        return results

# Streamlit UI
def create_image_to_video_ui():
    """Streamlit UIä½œæˆ"""
    
    st.title("ğŸ¬ ç”»åƒâ†’å‹•ç”»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ v5.0.0")
    st.markdown("Midjourney â†’ Klingï¼ˆæ—¥æœ¬äººå¥³æ€§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§ä¿æŒï¼‰")
    
    # åˆæœŸåŒ–
    if 'workflow' not in st.session_state:
        st.session_state.workflow = ImageToVideoWorkflow()
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    with st.form("workflow_form"):
        title = st.text_input("PVã‚¿ã‚¤ãƒˆãƒ«", value="ç¾ã—ã„æ—¥æœ¬ã®å››å­£")
        description = st.text_area(
            "æ¦‚è¦èª¬æ˜",
            value="æ—¥æœ¬äººå¥³æ€§ãŒå››å­£ã®ç§»ã‚Šå¤‰ã‚ã‚Šã¨ã¨ã‚‚ã«æˆé•·ã—ã¦ã„ãç‰©èª",
            height=100
        )
        duration = st.slider("å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰", 30, 300, 180)
        
        submitted = st.form_submit_button("ğŸš€ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹", type="primary")
    
    if submitted:
        with st.spinner("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œä¸­..."):
            results = st.session_state.workflow.execute_workflow(title, description, duration)
            
            # çµæœã‚’ä¿å­˜
            st.session_state.last_results = results
            
            st.success("âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†ï¼")
            st.balloons()

if __name__ == "__main__":
    create_image_to_video_ui()